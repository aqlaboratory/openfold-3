#
# This is a pixi (https://pixi.sh) manifest to manage environment for OpenFold-3.
#
# The current environment passes all tests in a linux machine.
# Change to the openfold-3 directory and run:
#   pixi run pytest -v .
#
# The environment can be exported to a regular conda yaml:
#  pixi workspace export conda-environment -n openfold3
# (note that at the moment this does not export environment variable definitios which we use here)
#
# If you have not pixi installed, please follow the instructions here:
#   https://pixi.sh/latest/installation/
# Which in linux boils down to run:
#   curl -fsSL https://pixi.sh/install.sh | sh
# And restart your shell.
#

[workspace]
name = "openfold3"
authors = []
channels = ["conda-forge", "bioconda"]
platforms = ["linux-64"]
version = "0.1.0"
# conda-pypi-map = {}

[activation]

# Trick deepspeed - we could also point to $CONDA_PREFIX
env.CUTLASS_PATH = "FAKE"

# --- Isolating completely the environment, including built extensions
# Note that this might not play well with advanced users or people who do not want to recompile
# So we likely do not want to enforce it or document it well

# Change triton cache to be local
env.TRITON_CACHE_DIR = "$CONDA_PREFIX/caches/triton"
# Change torch caches
env.TORCH_HOME = "$CONDA_PREFIX/caches/pytorch"
env.TORCH_EXTENSIONS_DIR = "$CONDA_PREFIX/caches/torch_extensions"
env.DS_BUILD_CACHE_DIR = "$CONDA_PREFIX/caches/deepspeed"

[system-requirements]
cuda = "12.0"

[dependencies]

# These are not really needed and get anyway installed
python = "*"
numpy = "*"
pandas = "*"

# --- Pytorch & its accelerators
# We could use pixi features to easily create CPU and GPU only envs
mkl = "*"
cuda-version = "<13"
pytorch-gpu = "*"

# --- More ML
ml-collections = "*"
pytorch-lightning = "*"

# --- DeepSpeed
deepspeed = "*"
ninja = "*"
cutlass = "*"

# These are only needed to build local extensions the first time
# Think on whether we want to delete them afterwards and how it would play with the user
cuda-minimal-build = "*"
libcusparse-dev = "*"
libcublas-dev = "*"
libcusolver-dev = "*"
libcurand-dev = "*"

# These are installed by pypi nvidia-cutlass
# But we want them to be conda-aware so they are compatible with our env
treelib = "*"
pydot = "*"
# This is needed to agree with the pin in openfold-3 dependencies
# This actually pins down other conda deps, and it is not needed in conda-world
cuda-python = "<12.9.1"

# --- Handling molecules
rdkit = "*"
biotite = "<1.3"
pdbeccdutils = "*"

# --- Bioinformatics & Workflows
hmmer = "*"
hhsuite = "*"
kalign2 = "*"
snakemake = "*"

# --- Misc
pyyaml = "*"
ijson = "*"
memory_profiler = "*"
wandb = "*"
func_timeout = "*"
tqdm = "*"
typing-extensions = "*"
python-lmdb = "*"

# --- Downloading stuff
requests = "*"
awscli = "*"
boto3 = "*"
aria2 = "*"

# --- Testing
pytest = "*"

# --- Dev and documentation optionals
# TODO: put in a pixi feature
ruff = "*"
sphinx = "*"
myst-parser = "*"
furo = "*"

# --- CuEquivariance optionals
# https://developer.nvidia.com/cuequivariance#section-get-started
# TODO: put in a pixi feature
# At the moment we also would need this that is only in pypi
#   * cuequivariance-ops-torch-cu12
# Which also pulls
#   * cuequivarance-ops-cu12
#   * nvidia-cublas-cu12
# We would need to also package this in conda-forge
cuequivariance = "*"
cuequivariance-torch = "*"

[pypi-dependencies]

# --- Poor native library detection from DeepSpeed

# DeepSpeed relies on python-cutlass
nvidia-cutlass = "==3.8"

# While this is closed (as they can now use pip check to test)
#   https://github.com/conda-forge/deepspeed-feedstock/issues/1
#   https://github.com/conda-forge/deepspeed-feedstock/pull/100
#   https://github.com/conda-forge/deepspeed-feedstock/commit/87cec8c4344b8eaefa3d17bffb69e2c83c28a82a
# DeepSpeed still cannot find conda-forge ninja, owing to this issue
#   https://github.com/conda-forge/ninja-feedstock/issues/26
ninja = "*"

# --- Missing package for cuequivariance
# At the moment the optimized kernels are not distributed in conda-forge
# Warning, this install some other python libs
cuequivariance-ops-torch-cu12 = "*"  # we need to coordinate this with the conda packages, or install all from pypi

# --- OpenFold3 in editable mode
# TODO: this brings a more modern version of MKL in python world which installs in parallel with the conda version
#       Figure out why this happens and how to avoid it
openfold3 = { path = ".", editable = true }