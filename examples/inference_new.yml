# predict.yml example

experiment_settings:
  mode: predict
  output_dir: ../test_train_output
  query_json: /path/
  inference_ckpt_path: /eagle/projects/MLProtein/jnwei/of3_checkpoints/last_converted.ckpt
  seeds:
    - 17
    - 42

data_module_args:
  batch_size: 1
  num_workers: 16
  num_gpus: 4
  epoch_len: 4

pl_trainer_args:
  num_nodes: 1
  precision: bf16-mixed
  max_epochs: 2
  log_every_n_steps: 2
  deepspeed_config_path: /ckpt/path.pt

# adjust the diffusion
model_update:
  preset: 
    - predict
  custom:
    settings:
      ...
      num_diffusion_samples: 50

#######
# MSA settings
#######
# Check with Gergo on how to organize msa related sections
# Interaction between msa interactions
use_msa_server: True

msa_server:
  host_url: https://api.colabfold.com
  user_agent: "openfold3/1.0.0"

# AF3 style MSAs
msa_databases:
  # list of named tuples / dict
  # use should specify the input
  name: /path/

dataset_config_kwargs:
  # to be converted into the full InferenceDatasetSpec
  # query_set: # empty for now, populate later 
  msa:
    n_rows: ...
  template:
    n_templates: 4


# Start with basic examples:
# 1. cli arguments
# 2. Using custom presets / small changes to inference yaml
# 3. Moving past custom presets

# Explain the hierarchy of the different levels of overwriting
# cli takes precedence
! run_openfold predict --use_msa_server \
                       --query_json /path/to/inference/query.json \
                       --output_dir /path/output \
                       --inference_ckpt_path /path/inference.ckpt \
                       # use this to update the model_update
                       --num_diffusion_samples 100 \  
                       --use_templates \
                       --runner_yaml /path/inference_runner.yml \
                    
! run_openfold predict --query_json /path/to/inference/query.json
                       --output_dir /path/output
                       --runner_yaml /path/inference_runner.yml